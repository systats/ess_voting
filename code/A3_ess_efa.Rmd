---
title: "ESS Factor Analysis"
subtitle: "Factor Scores"
author: "Rebecca & Simon "
output: html_notebook
---

## Packages

```{r}
pacman::p_load(dplyr, ggplot2, readr, haven, broom, purrr, tidyr, magrittr, labelled, sjPlot, viridis, forcats, ggthemes, cluster, factoextra, fpc)
ggplot2::theme_set(ggthemes::theme_few())
```

## Data

```{r}
ess <- get(load("data/Rdata/ess_final.Rdata")) %>%
  group_by(country) %>%
  mutate(id = paste0(iso2, 1:n())) %>%
  ungroup()
```


## Trust 

First we explore the diemnionality of the given trust items by applying standard pairwise scatterplots for euch variable combination and principal component analysis (efa) gain information on the distribution of variance in the data. After that conformatory factor analysis scores are computed for one trust dimesnion and merged for later analysis.


```{r}
trust_data_id <- ess %>%
  select(id, contains("trust")) %>%
  na.omit() 

trust_data <- trust_data_id %>% select(-id)
```

```{r}
library(GGally)

trust_scatter <- function(data, mapping, ...) {
  ggplot(data = data, mapping = mapping) +
    geom_jitter(alpha = .01, color = "#3D3D3D", size = .5) + 
    geom_smooth(mapping = mapping, method = "lm")
}

trust_hist <- function(data, mapping, ...) {
  ggplot(data = data, mapping = mapping) +
    geom_bar(fill = "#3D3D3D", width = 1)
}

pm <- ggpairs(
  trust_data, 
  #columns = c("total_bill", "time", "tip"),
  diag = list(continuous = wrap(trust_hist)),
  lower = list(
    #combo = wrap("facethist", binwidth = 1),
    continuous = wrap(trust_scatter)
  )
) 
trust_cor <- pm + theme_few()
#ggsave(trust_cor, filename = "images/trust_cor.png", height = 5, width = 7)
```

![](ggpairs_trust.png)


### PCA 

```{r}
fit_pca1 <- trust_data %>%
  scale() %>%
  prcomp()
```

```{r}
#sjt.pca(fit_pca1, nmbr.fctr = 1)
pca1_vis <- fviz_pca_var(fit_pca1, col.var = "black")

ess_pca1 <- ess %>%
  select(id, country) %>%
  dplyr::left_join(
    trust_data_id %>% 
      mutate(pc_trust = fit_pca1$x[,1]) %>%
      select(id, pc_trust)
  )

#ggsave(pca1_vis, filename = "images/pca1_vis.pdf")
```


```{r}
# Contributions of variables to PC1
trust_contr <- fviz_contrib(fit_pca1, choice = "var", axes = 1, top = 10, fill = "grey", color = NA)
### Screeplot: Eigenvalues
trust_scree <- fviz_eig(fit_pca1, addlabels = T,barfill = "grey", barcolor = NA)
library(gridExtra)
trust_eval <- grid.arrange(trust_scree, trust_contr, ncol = 2)
#ggsave(trust_eval, filename = "images/trust_eval.pdf", width = 10, height = 5)
```


## Immigration

And again we begin by exploring the diemnionality of immigration items by applying standard pairwise scatterplots for euch variable combination and principal component analysis to gain information on the distribution of variance in the data. After that the PC scores are extracted for the first immigration dimension and merged for later analysis.


```{r}
imm_data_id <- ess %>%
  select(id, contains("imm")) %>%
  mutate(imm_econ = (imm_econ-10)*-1) %>%
  na.omit() 

# summary(imm_data_id$imm_econ)
#(imm_data_id$imm_econ - 10)*-1

imm_data <- imm_data_id %>% select(-id)
```

```{r}
library(GGally)

trust_scatter <- function(data, mapping, ...) {
  ggplot(data = data, mapping = mapping) +
    geom_jitter(alpha = .01, color = "#3D3D3D", size = .5) + 
    geom_smooth(mapping = mapping, method = "lm")
}

trust_hist <- function(data, mapping, ...) {
  ggplot(data = data, mapping = mapping) +
    geom_bar(fill = "#3D3D3D", width = 1)
}

pm2 <- ggpairs(
  imm_data, 
  #columns = c("total_bill", "time", "tip"),
  diag = list(continuous = wrap(trust_hist)),
  lower = list(
    #combo = wrap("facethist", binwidth = 1),
    continuous = wrap(trust_scatter)
  )
) 
imm_cor <- pm2 + theme_few()
#ggsave(imm_cor, filename = "images/imm_cor.png", height = 5, width = 7)
```

### PCA 

```{r}
fit_pca2 <- imm_data %>%
  scale() %>%
  prcomp()
```

```{r}
#sjt.pca(fit_pca2, nmbr.fctr = 1)
pca2_vis <- fviz_pca_var(fit_pca2, col.var = "black")
#ggsave(pca2_vis, filename = "images/pca2_vis.pdf")

ess_pca2 <- ess %>%
  select(id, country) %>%
  dplyr::left_join(
    imm_data_id %>% 
      mutate(pc_imm = fit_pca2$x[,1],
             pc_imm_econ = fit_pca2$x[,2]) %>%
      select(id, pc_imm, pc_imm_econ)
  )

ess_scores <- ess %>% 
  left_join(ess_pca1) %>%
  left_join(ess_pca2)

#save(ess_scores, file = "data/Rdata/ess_scores.Rdata")
```


```{r}
# Contributions of variables to PC1
imm_contr <- fviz_contrib(fit_pca2, choice = "var", axes = 1, top = 10, fill = "grey", color = NA)
### Screeplot: Eigenvalues
imm_scree <- fviz_eig(fit_pca2, addlabels = T,barfill = "grey", barcolor = NA)
library(gridExtra)
imm_eval <- grid.arrange(imm_scree, imm_contr, ncol = 2)
#ggsave(imm_eval, filename = "images/imm_eval.pdf", width = 10, height = 5)
```











```{r}

# Color by cos2 values: quality on the factor map
fviz_pca_var(
  fit_pca1, 
  col.var = "cos2",
  gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
  repel = TRUE # Avoid text overlapping
)
# Graph of individuals
# fviz_pca_ind(fit_pca1)

# Total cos2 of variables on Dim.1 and Dim.2
fviz_cos2(fit_pca1, choice = "var", axes = 1:2)

# Contributions of variables to PC1
fviz_contrib(fit_pca1, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
#fviz_contrib(fit_pca1, choice = "var", axes = 2, top = 10)
# The total contribution to PC1 and PC2 is obtained with
#fviz_contrib(fit_pca1, choice = "var", axes = 1:3, top = 10)
```



## Factor Analysis

```{r}
fa_trust <- trust_data %>%
  factanal(., factors = 1, scores = 'regression')

trust_data_id$trust_scores <- fa_trust$scores[,1]
trust_data_id$trust_scores %>% head
```


```{r}
dd <- trust_data_id %>% select(id, trust_scores)
ess_score <- ess %>%
  dplyr::left_join(dd)

#save(ess_score, file = "data/Rdata/ess_score.Rdata")
```




* maximum likelihood estimation
* Assumptions: Each row $x_i$ of X is an independent sample from a
multivariate normal distribution, which has the density function:

$$f(x_i) = \frac{1}{2\pi^{p/2}|\Sigma|^{1/2}}e^{-\frac{1}{2}(x_i-\mu)^T\Sigma^{-1} (x_i-\mu)}$$

In addition, the covariance matrix is modelled by a structure of common factors accounting for a joint component of variance and specific residual variances for each variable:

$$\Sigma = \Lambda\Lambda^T + D_\psi$$

Need to first: write out the likelihood, and then maximize it!!!
*Easier* to start with a one-factor solution...

$$\Sigma = \lambda\lambda^T + D_\psi$$

* The proportion of the variance in each original variable $x_d$ accounted for by the first $PC_1$ given by the sum of the squared factor loadings; that is $\sum^c_{k=1} f^2_{ik}$. When c=p (all components are retained). $$\sum^c_{k=1} f^2_{ik}=1$ (all variance is explained)

* Factor loadings are the correlations between the original variables x and the components PC, denoted as $F = cor(x, PC) = uD^{1/2}$. Internal Validation measure to see the correlation between predictors and extracted components.


### Factor Rotations

The factor loadings matrix is usually rotated or re-oriented in order to receive uncorrelated factors/ components. The goal is to find clusters of variables that are highly correlated and to large extend define only one factor. 

* **Orthogonal rotation:** preserves the perpendicularity of the axes (remain uncorrelated)
    + **Varimax**: preserves simple structure by focusing on the columns of the factor loadings matrix. The Kaiser`s varimax rotation aims to maximize the independent squared loadings variance across variables summed over all factors.
    + **Quartimax** rotation - preserves simple structure by focusing on the rows of the factor loading matrix
* **Oblique rotation - allows for correlation between the rotated factors. The purpose is to align th efactor axes as closely as possible to the groups of the original variables. The goal is to facilitate the interpretation of the results (more distrimative).
  * **Promax rotation**


Common factor model - observed variance in each measure is attributable to a relatively small number of common factors and a single speficif factor (uncorrelated to other factors in the model). 

my opinion 

$$x_{i1} = \lambda_1\xi_{i1} + \lambda_2\xi_{i2} + ... + \delta_i  $$

her opinion:

$$x_{i} = \lambda_{i1}\xi_1 + \lambda_{i2}\xi_2 + ... + \delta_i  $$


The common analysis is appropriate when there is a *latent trait* or unobservable characteristics. Used within suervey questions about attitudes. The goal is to identify common factors captering the variance from these questions and which can also be used as factor scores.

* Assumptions to determine a solution to the common factor model:
    + The common factors are uncorrelated with each other
    + The specific factors are uncorrelated with each other.
    + The common factors and specific factors are uncorrelated with each other. 
    
* The communality is the proportion of variance in X attributable to the common factors

$$h_i^2 = \sum_k \lambda^2_{ik} = 1- \theta_{ik}^2$$
where $\theta_{ik}^2 = var(\delta_i)$ is the fcator uniqueness. 
* The solution to the common factor model is determined by orienting the first factor so that it captures the greatest possible varinace but is uncorrelated with the first factor.
* The correlation between X variables and the ... factors are called loadings $\Lambda$.
* The factor scores present the psoitions of the observations in the common factor space. The factpr score coefficients are given by 

$$B = R^{-1}\Lambda_c$$

where R is the correlation matrix
* The factor scores are calculated as:

$$\Xi = X_SB$$
These factor scores are included in the data and can be used instead of the original variables. 




```{r, eval = F}
library(ggplot2)
library(survival)
data(lung, package = "survival")
summary(ess$rel)
ess_surv <- ess
ess_surv$year <- 2017 - ess_surv$year 
sf.ess <- survival::survfit(Surv(year, gndr) ~ 1, data = ess_surv)
ggsurv(sf.ess)
```

